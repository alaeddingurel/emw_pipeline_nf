all_components=true # true-> all_components branch , false -> hpc branch
gpu_classifier=0-3 # number or range of gpu/s given to document classifier
gpu_sentences=6 # number or range of gpu/s given to sentence classifier
gpu_token=7 #number or range of gpu/s given to token classifier
#GPUS 3,4,5 are given to semantics classifiers.
input="/scratch/10kpeoplesDaily_en_news" # the path of input folder ### without backslash in the end
output="/home/aalabrash18/pipeline_experiments/people/jsons/" # path of the output folder 
resume=true # nextflow parameter, check https://www.nextflow.io/docs/latest/getstarted.html for more information
files_start_with="*" #file name pattern that are in input folder. * means all the files under the input folder given . http* those file start with http
source_lang="English" # source language
source=3 # source number 
doc_batchsize=30 #document classifier batch size
token_batchsize=8 # token classifier batch size

prefix="/home/aalabrash18/emw_pipeline_nf" # where pipeline scripts are
#out_to_csv script's parameters 
out_output_type=csv #type of output
out_name_output_file=outfile # name of outfile 
out_date_key= 'time' # name of the column the contains time/date information in the dataset , =time in thehindu dataset! 
filter_unprotested_sentence=False #report only sentence that predicted as protest and skip the non-protest sentence. 
filter_unprotested_documents=False #report only documents that predicted as protest and skip the non-protest documents.

#TODO : add docs to each parameter
#add python path parameter
#change prefix to work_space/ module path/ 
#add the port/ip of each flask API as parameter